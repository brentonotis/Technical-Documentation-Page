<script src="https://cdn.freecodecamp.org/testable-projects-fcc/v1/bundle.js"></script>

<script defer src="https://use.fontawesome.com/releases/v5.0.6/js/all.js"></script>

<nav>
  <header class="menu-header">Big-What? (Oh...)</header>
  <ul>
    <a class="nav-link" href="#what"><li>What is it?</li></a>
    <a class="nav-link" href="#"><li>Why use it?</li></a>
    <a class="nav-link" href="#"><li>How to use it?</li></a>
    <a class="nav-link" href="#"><li>Measuring growth rate</li></a>
    <a class="nav-link" href="#"><li>Common growth rates</li></a>
    <a class="nav-link" href="#"><li>Disadvantageous</li></a>
    <a class="nav-link" href="#"><li>References</li></a>
  </ul>
</nav>
<main id="main-doc">
  <section class="main-section" id="what">
    <header>What is it?</header>
    <article>
      <p>Big-O refers to the notation typically used by computer scientists to represent/analyze the complexity of an algorithm (1). In other words, Big-O is used to determine how efficient an algorithm will run. While this may seem a mute point with algorithms computing small datasets, as there may seem to be no difference to the naked eye, an algorithms complexity (specifically time-complexity for our purposes) can have significant impact on performance (speed) as datasets scale. For this reason, Big-O notation is utilized to determine how efficiently an algorithm will perform at scale (and/or in the worst-case scenario).</p>
    </article>
  </section>
  <section class="main-section" id="why">
    <header>Why use it?</header>
    <article>
      <p>A major advantage in using Big-O to analyze algorithms revolves around the 'work smarter not harder' concept. As alluded to, when initially developing an algorithm for a program, it may seem to perform with acceptable performance on a smaller/test dataset. However, when deployed at scale with datasets much larger in size, the programmer might find that the algorithm actually performs exponentially slower than originally presumed.</p>
      <p>In a real-life scenario of developing a complex program (and/or simple program that will involve large/massive data sets and require optimal latency), analyzing an algorithms complexity ahead of time (via Big-O) can prevent these unexpected consequences and save time/reduce extra work required on the programmer's behalf down the road. This kind of complexity analysis can also aid in understanding overall program performance prior to actually writing any code.</p>
    </article>
  </section>
  <section class="main-section" id="how">
    <header>How to use it?</header>
    <article>
      <p> abc </p>
      <p> xyz </p>
    </article>
  </section>
  <section class="main-section" id="measuring">
    <header>Measuring growth rate</header>
    <article>
      <p> abc </p>
      <p> xyz </p>
    </article>
  </section>
  <section class="main-section" id="common">
    <header>Common growth rates</header>
    <article>
      <p> abc </p>
      <p> xyz </p>
    </article>
  </section>
  <section class="main-section" id="disadvantageous">
    <header>Disadvantageous</header>
    <article>
      <p> abc </p>
      <p> xyz </p>
    </article>
  </section>
  <section class="main-section" id="measuring">
    <header>References</header>
    <article>
      <ul>
        <li> ref1 </li>
        <li> ref2 </li>
        <li> ref3 </li>
        <li> ref4 </li>
      </ul>
    </article>
  </section>
</main>
<footer class="footer"> A <a href="https://www.freecodecamp.org" target="_blank"><img id="img1" src="https://raw.githubusercontent.com/FreeCodeCamp/assets/master/assets/logos/fcc_puck600.png"></a> project<br><p> Coded with <i class="fas fa-hand-peace"></i><i class="fas fa-heart"></i> and <i class="fas fa-hand-rock"></i> by <a class="brenton" href="https://www.linkedin.com/in/brentonotis/Brenton Otis" target="_blank">Brenton</a></p>
</footer>